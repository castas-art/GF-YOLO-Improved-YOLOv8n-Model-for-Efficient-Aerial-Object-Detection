# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""Module defines the base classes and structures for object tracking in YOLO."""
import numpy as np
import cv2

from ..utils import LOGGER
from ..utils.ops import xywh2ltwh
from .basetrack import BaseTrack, TrackState
from .utils import matching
from .utils.kalman_filter import KalmanFilterXYAH  # å¯¼å…¥æ‚¨çš„å¡å°”æ›¼æ»¤æ³¢å™¨
from .Opt_Flow import MaskedOpticalFlow


class STrack(BaseTrack):
    """
    Single object tracking representation that uses Kalman filtering for state estimation.
    """

    shared_kalman = KalmanFilterXYAH()

    def __init__(self, xywh, score, cls):
        """
        Initialize a new STrack instance.
        """
        super().__init__()
        # xywh+idx or xywha+idx
        assert len(xywh) in {5, 6}, f"expected 5 or 6 values but got {len(xywh)}"
        self._tlwh = np.asarray(xywh2ltwh(xywh[:4]), dtype=np.float32)
        self.kalman_filter = None
        self.mean, self.covariance = None, None
        self.is_activated = False

        self.score = score
        self.tracklet_len = 0
        self.cls = cls
        self.idx = xywh[-1]
        self.angle = xywh[4] if len(xywh) == 6 else None

    def predict(self):
        """Predicts the next state (mean and covariance) of the object using the Kalman filter."""
        mean_state = self.mean.copy()
        if self.state != TrackState.Tracked:
            mean_state[7] = 0
        self.mean, self.covariance = self.kalman_filter.predict(mean_state, self.covariance)

    @staticmethod
    def multi_predict(stracks):
        """Perform multi-object predictive tracking using Kalman filter for the provided list of STrack instances."""
        if len(stracks) <= 0:
            return
        multi_mean = np.asarray([st.mean.copy() for st in stracks])
        multi_covariance = np.asarray([st.covariance for st in stracks])
        for i, st in enumerate(stracks):
            if st.state != TrackState.Tracked:
                multi_mean[i][7] = 0
        multi_mean, multi_covariance = STrack.shared_kalman.multi_predict(multi_mean, multi_covariance)
        for i, (mean, cov) in enumerate(zip(multi_mean, multi_covariance)):
            stracks[i].mean = mean
            stracks[i].covariance = cov

    @staticmethod
    def multi_gmc(stracks, H=np.eye(2, 3)):
        """Update state tracks positions and covariances using a homography matrix for multiple tracks."""
        if len(stracks) > 0:
            multi_mean = np.asarray([st.mean.copy() for st in stracks])
            multi_covariance = np.asarray([st.covariance for st in stracks])

            R = H[:2, :2]
            R8x8 = np.kron(np.eye(4, dtype=float), R)
            t = H[:2, 2]

            for i, (mean, cov) in enumerate(zip(multi_mean, multi_covariance)):
                mean = R8x8.dot(mean)
                mean[:2] += t
                cov = R8x8.dot(cov).dot(R8x8.transpose())

                stracks[i].mean = mean
                stracks[i].covariance = cov

    def activate(self, kalman_filter, frame_id):
        """Activate a new tracklet using the provided Kalman filter and initialize its state and covariance."""
        self.kalman_filter = kalman_filter
        self.track_id = self.next_id()
        self.mean, self.covariance = self.kalman_filter.initiate(self.convert_coords(self._tlwh))

        self.tracklet_len = 0
        self.state = TrackState.Tracked
        if frame_id == 1:
            self.is_activated = True
        self.frame_id = frame_id
        self.start_frame = frame_id

    def re_activate(self, new_track, frame_id, new_id=False):
        """Reactivates a previously lost track using new detection data and updates its state and attributes."""
        self.mean, self.covariance = self.kalman_filter.update(
            self.mean, self.covariance, self.convert_coords(new_track.tlwh)
        )
        self.tracklet_len = 0
        self.state = TrackState.Tracked
        self.is_activated = True
        self.frame_id = frame_id
        if new_id:
            self.track_id = self.next_id()
        self.score = new_track.score
        self.cls = new_track.cls
        self.angle = new_track.angle
        self.idx = new_track.idx

    def update(self, new_track, frame_id):
        """
        Update the state of a matched track.
        """
        self.frame_id = frame_id
        self.tracklet_len += 1

        new_tlwh = new_track.tlwh
        self.mean, self.covariance = self.kalman_filter.update(
            self.mean, self.covariance, self.convert_coords(new_tlwh)
        )
        self.state = TrackState.Tracked
        self.is_activated = True

        self.score = new_track.score
        self.cls = new_track.cls
        self.angle = new_track.angle
        self.idx = new_track.idx

    def convert_coords(self, tlwh):
        """Convert a bounding box's top-left-width-height format to its x-y-aspect-height equivalent."""
        return self.tlwh_to_xyah(tlwh)

    @property
    def tlwh(self):
        """Returns the bounding box in top-left-width-height format from the current state estimate."""
        if self.mean is None:
            return self._tlwh.copy()
        ret = self.mean[:4].copy()
        ret[2] *= ret[3]
        ret[:2] -= ret[2:] / 2
        return ret

    @property
    def xyxy(self):
        """Converts bounding box from (top left x, top left y, width, height) to (min x, min y, max x, max y) format."""
        ret = self.tlwh.copy()
        ret[2:] += ret[:2]
        return ret

    @staticmethod
    def tlwh_to_xyah(tlwh):
        """Convert bounding box from tlwh format to center-x-center-y-aspect-height (xyah) format."""
        ret = np.asarray(tlwh).copy()
        ret[:2] += ret[2:] / 2
        ret[2] /= ret[3]
        return ret

    @property
    def xywh(self):
        """Returns the current position of the bounding box in (center x, center y, width, height) format."""
        ret = np.asarray(self.tlwh).copy()
        ret[:2] += ret[2:] / 2
        return ret

    @property
    def xywha(self):
        """Returns position in (center x, center y, width, height, angle) format, warning if angle is missing."""
        if self.angle is None:
            LOGGER.warning("WARNING âš ï¸ `angle` attr not found, returning `xywh` instead.")
            return self.xywh
        return np.concatenate([self.xywh, self.angle[None]])

    @property
    def result(self):
        """Returns the current tracking results in the appropriate bounding box format."""
        coords = self.xyxy if self.angle is None else self.xywha
        return coords.tolist() + [self.track_id, self.score, self.cls, self.idx]

    def __repr__(self):
        """Returns a string representation of the STrack object including start frame, end frame, and track ID."""
        return f"OT_{self.track_id}_({self.start_frame}-{self.end_frame})"


class BYTETracker:
    """
    BYTETracker with optical flow compensation for camera motion
    """

    def __init__(self, args, frame_rate=30):
        """
        Initialize a BYTETracker instance for object tracking.
        """
        self.tracked_stracks = []  # type: list[STrack]
        self.lost_stracks = []  # type: list[STrack]
        self.removed_stracks = []  # type: list[STrack]

        self.frame_id = 0
        self.args = args

        self.max_time_lost = int(frame_rate / 30.0 * args.track_buffer)
        self.kalman_filter = self.get_kalmanfilter()
        self.reset_id()

        # å…‰æµè¡¥å¿ç›¸å…³åˆå§‹åŒ–
        self.flow_calculator = MaskedOpticalFlow(
            max_corners=100,
            quality_level=0.01,
            min_distance=10
        )

        # è¡¥å¿çŠ¶æ€å˜é‡
        self.last_velocity = (0, 0)
        self.reference_velocity = None
        self.in_compensation_mode = False
        self.compensation_scale = 0.5  # è¡¥å¿ç³»æ•°

        # å¡å°”æ›¼æ»¤æ³¢å‚æ•°åŠ¨æ€è°ƒèŠ‚
        self.default_match_thresh = getattr(args, 'match_thresh', 0.8)
        self.max_match_thresh = 0.9
        self.min_match_thresh = 0.3
        self.max_noise_scale = 5.0

        # å§‹ç»ˆå¯ç”¨å¢å¼ºçš„å¡å°”æ›¼æ»¤æ³¢å‚æ•°
        self.kalman_filter.noise_scale_factor = self.max_noise_scale  # ç›´æ¥è®¾ç½®ä¸ºæœ€å¤§å€¼

        # è®¾ç½®è¾ƒå®½æ¾çš„åŒ¹é…é˜ˆå€¼
        self.args.match_thresh = self.max_match_thresh  # ç›´æ¥ä½¿ç”¨æœ€å¤§åŒ¹é…é˜ˆå€¼

        # è®°å½•åŸå§‹æ ‡å¿—
        self.always_adaptive = False  # æ–°å¢æ ‡å¿—ï¼Œè¡¨ç¤ºå§‹ç»ˆä½¿ç”¨è‡ªé€‚åº”æ¨¡å¼

        # å­˜å‚¨åŸå§‹å‚æ•°ï¼Œç”¨äºæ¢å¤
        self.default_noise_scale = getattr(self.kalman_filter, 'noise_scale_factor', 1.0)

        # æ˜¯å¦æ˜¾ç¤ºè¡¥å¿å‰åå¯¹æ¯”
        self.show_compensation = True
        # ä¿å­˜æœ€è¿‘å¤„ç†çš„å¸§
        self.current_frame = None
        # ä¿å­˜è¾“å‡ºçª—å£åç§°
        self.window_name = "BYTETracker Compensation"
        self.use_gmc = False

    def update(self, results, img=None):
        """Updates the tracker with new detections and returns the current list of tracked objects."""
        self.frame_id += 1
        activated_stracks = []
        refind_stracks = []
        lost_stracks = []
        removed_stracks = []

        # ä¿å­˜å½“å‰å¸§
        if img is not None:
            self.current_frame = img.copy()

        # è·å–æ£€æµ‹ç»“æœ
        scores = results.conf
        bboxes = results.xywhr if hasattr(results, "xywhr") else results.xywh
        # Add index
        bboxes = np.concatenate([bboxes, np.arange(len(bboxes)).reshape(-1, 1)], axis=-1)
        cls = results.cls

        # å­˜å‚¨è¡¥å¿å‰çš„æ¡†ä½ç½®
        pre_compensation_boxes = []

        # å¦‚æœæä¾›äº†å›¾åƒï¼Œè®¡ç®—å…‰æµå¹¶åº”ç”¨è¡¥å¿
        flow_result = {"is_valid": False, "translation_vector": (0, 0)}
        if img is not None:
            # å‡†å¤‡æ£€æµ‹æ¡†æ ¼å¼ç”¨äºå…‰æµæ©ç 
            xyxy_boxes = []
            for i, box in enumerate(bboxes):
                x, y, w, h = box[:4]
                x1, y1 = x - w / 2, y - h / 2
                x2, y2 = x + w / 2, y + h / 2
                xyxy_boxes.append([x1, y1, x2, y2])

            # è®¡ç®—å…‰æµ
            flow_result = self.flow_calculator.compute(img, xyxy_boxes)

        # æŒ‰é˜ˆå€¼åˆ†ç±»æ£€æµ‹æ¡†
        remain_inds = scores >= self.args.track_high_thresh
        inds_low = scores > self.args.track_low_thresh
        inds_high = scores < self.args.track_high_thresh

        inds_second = inds_low & inds_high
        dets_second = bboxes[inds_second]
        dets = bboxes[remain_inds]
        scores_keep = scores[remain_inds]
        scores_second = scores[inds_second]
        cls_keep = cls[remain_inds]
        cls_second = cls[inds_second]

        # åˆå§‹åŒ–è·Ÿè¸ªå™¨
        detections = self.init_track(dets, scores_keep, cls_keep, img)

        # è·å–ç¡®è®¤å’Œæœªç¡®è®¤çš„è½¨è¿¹
        unconfirmed = []
        tracked_stracks = []  # type: list[STrack]
        for track in self.tracked_stracks:

            if not track.is_activated:
                unconfirmed.append(track)
            else:
                tracked_stracks.append(track)

        # åˆ›å»ºè·Ÿè¸ªæ± 
        strack_pool = self.joint_stracks(tracked_stracks, self.lost_stracks)

        # # åœ¨åº”ç”¨å…‰æµè¡¥å¿å‰è®°å½•æ‰€æœ‰è·Ÿè¸ªæ¡†ä½ç½®
        # if flow_result['is_valid']:
        #     for track in strack_pool:
        #         if track.is_activated:
        #             pre_compensation_boxes.append(track.result.copy())  # ä¿å­˜è¡¥å¿å‰çš„ç»“æœ

        # é¢„æµ‹å½“å‰ä½ç½®
        self.multi_predict(strack_pool)

        # åº”ç”¨å…‰æµè¡¥å¿
        if flow_result['is_valid']:
            self._apply_flow_compensation(flow_result)

        if flow_result['is_valid']:
         for track in strack_pool:
                if track.is_activated:
                     pre_compensation_boxes.append(track.result.copy())  # ä¿å­˜è¡¥å¿å‰çš„ç»“æœ

        # å¦‚æœæœ‰GMCä¸”ä¼ å…¥å›¾åƒï¼Œåº”ç”¨GMCï¼ˆå…¼å®¹å·²æœ‰GMCï¼‰
        """
        if hasattr(self, "gmc") and img is not None and not self.in_compensation_mode and self.use_gmc:
            warp = self.gmc.apply(img, dets)
            STrack.multi_gmc(strack_pool, warp)
            STrack.multi_gmc(unconfirmed, warp)
        """

        # ç¬¬ä¸€è½®å…³è”ï¼šé«˜åˆ†æ£€æµ‹æ¡†
        dists = self.get_dists(strack_pool, detections)
        matches, u_track, u_detection = matching.linear_assignment(dists, thresh=self.args.match_thresh)

        for itracked, idet in matches:
            track = strack_pool[itracked]
            det = detections[idet]
            if track.state == TrackState.Tracked:
                track.update(det, self.frame_id)
                activated_stracks.append(track)
            else:
                track.re_activate(det, self.frame_id, new_id=False)
                refind_stracks.append(track)

        # ç¬¬äºŒè½®å…³è”ï¼šä½åˆ†æ£€æµ‹æ¡†
        detections_second = self.init_track(dets_second, scores_second, cls_second, img)
        r_tracked_stracks = [strack_pool[i] for i in u_track if strack_pool[i].state == TrackState.Tracked]

        dists = matching.iou_distance(r_tracked_stracks, detections_second)
        matches, u_track, u_detection_second = matching.linear_assignment(dists, thresh=0.5)
        for itracked, idet in matches:
            track = r_tracked_stracks[itracked]
            det = detections_second[idet]
            if track.state == TrackState.Tracked:
                track.update(det, self.frame_id)
                activated_stracks.append(track)
            else:
                track.re_activate(det, self.frame_id, new_id=False)
                refind_stracks.append(track)

        # å¤„ç†æœªåŒ¹é…è½¨è¿¹
        for it in u_track:
            track = r_tracked_stracks[it]
            if track.state != TrackState.Lost:
                track.mark_lost()
                lost_stracks.append(track)

        # å¤„ç†æœªç¡®è®¤è½¨è¿¹
        detections = [detections[i] for i in u_detection]
        dists = self.get_dists(unconfirmed, detections)
        matches, u_unconfirmed, u_detection = matching.linear_assignment(dists, thresh=0.7)
        for itracked, idet in matches:
            unconfirmed[itracked].update(detections[idet], self.frame_id)
            activated_stracks.append(unconfirmed[itracked])
        for it in u_unconfirmed:
            track = unconfirmed[it]
            track.mark_removed()
            removed_stracks.append(track)

        # åˆ›å»ºæ–°è½¨è¿¹
        for inew in u_detection:
            track = detections[inew]
            if track.score < self.args.new_track_thresh:
                continue
            track.activate(self.kalman_filter, self.frame_id)
            activated_stracks.append(track)

        # æ›´æ–°è½¨è¿¹çŠ¶æ€
        for track in self.lost_stracks:
            if self.frame_id - track.end_frame > self.max_time_lost:
                track.mark_removed()
                removed_stracks.append(track)

        # æ›´æ–°è½¨è¿¹åˆ—è¡¨
        self.tracked_stracks = [t for t in self.tracked_stracks if t.state == TrackState.Tracked]
        self.tracked_stracks = self.joint_stracks(self.tracked_stracks, activated_stracks)
        self.tracked_stracks = self.joint_stracks(self.tracked_stracks, refind_stracks)
        self.lost_stracks = self.sub_stracks(self.lost_stracks, self.tracked_stracks)
        self.lost_stracks.extend(lost_stracks)
        self.lost_stracks = self.sub_stracks(self.lost_stracks, self.removed_stracks)
        self.tracked_stracks, self.lost_stracks = self.remove_duplicate_stracks(self.tracked_stracks, self.lost_stracks)
        self.removed_stracks.extend(removed_stracks)
        if len(self.removed_stracks) > 1000:
            self.removed_stracks = self.removed_stracks[-999:]  # clip remove stracks to 1000 maximum

        # è·å–è¡¥å¿åçš„æ¡†
        post_compensation_boxes = [x.result for x in self.tracked_stracks if x.is_activated]

        # å¦‚æœæœ‰å›¾åƒä¸”æœ‰è¡¥å¿å‰çš„æ¡†ï¼Œç»˜åˆ¶è¡¥å¿å¯¹æ¯”
        if img is not None and len(pre_compensation_boxes) > 0 and self.show_compensation:
            vis_img = self._visualize_compensation(img, np.array(pre_compensation_boxes),
                                                   np.array(post_compensation_boxes))
            cv2.imshow(self.window_name, vis_img)
            cv2.waitKey(50)  # æ˜¾ç¤º1æ¯«ç§’

        # è¿”å›æ ‡å‡†æ ¼å¼ç»“æœ
        return np.asarray(post_compensation_boxes, dtype=np.float32)

    def _visualize_compensation(self, img, pre_boxes, post_boxes):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶è¡¥å¿å‰åçš„è¾¹ç•Œæ¡†
        """
        # å¤åˆ¶å›¾åƒä»¥å…ä¿®æ”¹åŸå›¾
        vis_img = img.copy()

        # ç»˜åˆ¶è¡¥å¿å‰çš„æ¡†ï¼ˆçº¢è‰²ï¼‰
        if pre_boxes is not None and len(pre_boxes) > 0:
            for box in pre_boxes:
                if len(box) >= 8:  # æ ‡å‡†æ ¼å¼
                    if len(box) == 9:  # å¸¦è§’åº¦çš„æ¡†
                        cx, cy, w, h, angle = box[:5]
                        # ç»˜åˆ¶æ—‹è½¬æ¡†ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        rect = ((cx, cy), (w, h), angle * 180 / np.pi if np.isscalar(angle) else angle)
                        points = cv2.boxPoints(rect).astype(np.int32)
                        cv2.polylines(vis_img, [points], True, (0, 0, 255), 2)  # çº¢è‰²
                    else:
                        x1, y1, x2, y2 = box[:4]
                        cv2.rectangle(vis_img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)  # çº¢è‰²

                    # ç»˜åˆ¶ID
                    track_id = int(box[-4])
                    cv2.putText(vis_img, f"ID:{track_id}", (int(box[0]), int(box[1]) - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

        # ç»˜åˆ¶è¡¥å¿åçš„æ¡†ï¼ˆç»¿è‰²ï¼‰
        if post_boxes is not None and len(post_boxes) > 0:
            for box in post_boxes:
                if len(box) >= 8:  # æ ‡å‡†æ ¼å¼
                    if len(box) == 9:  # å¸¦è§’åº¦çš„æ¡†
                        cx, cy, w, h, angle = box[:5]
                        # ç»˜åˆ¶æ—‹è½¬æ¡†
                        rect = ((cx, cy), (w, h), angle * 180 / np.pi if np.isscalar(angle) else angle)
                        points = cv2.boxPoints(rect).astype(np.int32)
                        cv2.polylines(vis_img, [points], True, (0, 255, 0), 2)  # ç»¿è‰²
                    else:
                        x1, y1, x2, y2 = box[:4]
                        cv2.rectangle(vis_img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)  # ç»¿è‰²

                    # ç»˜åˆ¶ID
                    track_id = int(box[-4])
                    cv2.putText(vis_img, f"ID:{track_id}", (int(box[0]), int(box[1]) + 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # æ˜¾ç¤ºä¿¡æ¯
        cv2.putText(vis_img, "Pre-compensation (Red)", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        cv2.putText(vis_img, "Post-compensation (Green)", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        return vis_img

    def _apply_flow_compensation(self, flow_result):
        """åº”ç”¨å…‰æµè¡¥å¿åˆ°è·Ÿè¸ªå™¨çŠ¶æ€"""
        # è·å–å½“å‰å…‰æµé€Ÿåº¦
        tx, ty = flow_result["translation_vector"]
        acceleration_threshold = 7.0
        ks = 1

        # ä¿æŒå¢å¼ºçš„å¡å°”æ›¼æ»¤æ³¢å‚æ•°
        self.always_adaptive=False
        if self.always_adaptive:
            self.kalman_filter.noise_scale_factor = self.max_noise_scale
            self.args.match_thresh = self.max_match_thresh

        # è®¡ç®—åŠ é€Ÿåº¦
        if hasattr(self, 'last_velocity') and self.last_velocity != (0, 0):  # éç¬¬ä¸€å¸§
            ax_abs = tx - self.last_velocity[0]
            ay_abs = ty - self.last_velocity[1]
            acceleration_magnitude = np.sqrt(ax_abs ** 2 + ay_abs ** 2)

            # åˆå§‹å¸§å¤„ç†
            if self.frame_id <= 3:
                self.last_velocity = (tx, ty)
                return

            # æ£€æµ‹çªå˜å¹¶å¯åŠ¨è¡¥å¿æ¨¡å¼
            if not self.in_compensation_mode and acceleration_magnitude > acceleration_threshold:
                self.reference_velocity = self.last_velocity
                self.in_compensation_mode = True
                LOGGER.info(f"æ£€æµ‹åˆ°çªå˜! åŠ é€Ÿåº¦={acceleration_magnitude:.2f}, å‚è€ƒé€Ÿåº¦={self.reference_velocity}")


                #     # å¢å¤§å¡å°”æ›¼æ»¤æ³¢è¿‡ç¨‹å™ªå£°
                if hasattr(self.kalman_filter, 'noise_scale_factor'):
                       self.kalman_filter.noise_scale_factor = min(
                             self.kalman_filter.noise_scale_factor * 2.0,
                            self.max_noise_scale
                        )
                    # æ”¾å®½åŒ¹é…é˜ˆå€¼
                self.args.match_thresh = min(
                        self.args.match_thresh * 1.5,
                        self.max_match_thresh
                     )
                #     LOGGER.info(
                #         f"åœºæ™¯å˜åŒ–: å™ªå£°å°ºåº¦={self.kalman_filter.noise_scale_factor:.2f}, åŒ¹é…é˜ˆå€¼={self.args.match_thresh:.2f}")

                # æ£€æµ‹çªå˜å¹¶å¯åŠ¨è¡¥å¿æ¨¡å¼

            # æ‰§è¡Œè¡¥å¿
            if self.in_compensation_mode:
                dx_compensation = 0
                dy_compensation = 0

                # Xæ–¹å‘è¡¥å¿è®¡ç®—
                if abs(tx - self.reference_velocity[0]) > 5.0:
                    if tx * self.reference_velocity[0] >= 0:  # æ–¹å‘ç›¸åŒ
                        dx_compensation = (tx - self.reference_velocity[0]) * ks
                    else:  # æ–¹å‘æ”¹å˜
                        if tx > 0:
                            dx_compensation = (tx + abs(self.reference_velocity[0])) * ks
                        else:
                            dx_compensation = (tx - self.reference_velocity[0]) * ks

                # Yæ–¹å‘è¡¥å¿
                if abs(ty - self.reference_velocity[1]) > 5.0:
                    if ty * self.reference_velocity[1] >= 0:
                        dy_compensation = (ty - self.reference_velocity[1]) * ks
                    else:
                        if ty > 0:
                            dy_compensation = (ty + abs(self.reference_velocity[1])) * ks
                        else:
                            dy_compensation = (ty - self.reference_velocity[1]) * ks

                # åº”ç”¨è¡¥å¿åˆ°æ‰€æœ‰è½¨è¿¹
                if abs(dx_compensation) > 0 or abs(dy_compensation) > 0:
                    LOGGER.info(f"åº”ç”¨è¡¥å¿: dx={dx_compensation:.2f}, dy={dy_compensation:.2f}")
                    for track in self.tracked_stracks + self.lost_stracks:
                        if track.mean is not None:

                            track.mean[0] += dx_compensation  # ä½ç½®x
                            track.mean[1] += dy_compensation  # ä½ç½®y



                # æ£€æŸ¥æ˜¯å¦é€€å‡ºè¡¥å¿æ¨¡å¼
                velocity_close = (abs(tx - self.reference_velocity[0]) < 2.0 and
                                  abs(ty - self.reference_velocity[1]) < 2.0)

                current_ax_abs = abs(tx - self.reference_velocity[0]) - abs(
                    self.last_velocity[0] - self.reference_velocity[0])
                current_ay_abs = abs(ty - self.reference_velocity[1]) - abs(
                    self.last_velocity[1] - self.reference_velocity[1])
                current_acc_magnitude = np.sqrt(current_ax_abs ** 2 + current_ay_abs ** 2)



                if velocity_close or current_acc_magnitude < 0.3 * acceleration_threshold:
                    LOGGER.info("é€€å‡ºè¡¥å¿æ¨¡å¼ï¼Œé€Ÿåº¦å·²æ¢å¤ç¨³å®š")
                    self.in_compensation_mode = False

                    """

                    # é€Ÿåº¦è¡¥å¿
                    x = self.last_velocity[0] - self.reference_velocity[0]
                    y = self.last_velocity[1] - self.reference_velocity[1]

                    if abs(x) > 10:
                        LOGGER.info(f"Xé€Ÿåº¦è¡¥å¿: {x * ks:.2f}")
                        for track in self.tracked_stracks + self.lost_stracks:
                            if track.mean is not None:
                                track.mean[4] += x * ks  # é€Ÿåº¦x

                    if abs(y) > 10:
                        LOGGER.info(f"Yé€Ÿåº¦è¡¥å¿: {y * ks:.2f}")
                        for track in self.tracked_stracks + self.lost_stracks:
                            if track.mean is not None:
                                track.mean[5] += y * ks  # é€Ÿåº¦y
                 """

                    # åœºæ™¯ç¨³å®šæ—¶æ¢å¤é»˜è®¤å‚æ•°

                    self.args.match_thresh = max(
                             self.args.match_thresh / 1.5,
                            self.default_match_thresh
                         )
                    if hasattr(self.kalman_filter, 'noise_scale_factor'):
                             self.kalman_filter.noise_scale_factor = self.default_noise_scale

                    self.reference_velocity = None

        # æ›´æ–°é€Ÿåº¦è®°å½•
        self.last_velocity = (tx, ty)

    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜...

    def get_kalmanfilter(self):
        """Returns a Kalman filter object for tracking bounding boxes using KalmanFilterXYAH."""
        return KalmanFilterXYAH()

    def init_track(self, dets, scores, cls, img=None):
        """Initializes object tracking with given detections, scores, and class labels using the STrack algorithm."""
        return [STrack(xyxy, s, c) for (xyxy, s, c) in zip(dets, scores, cls)] if len(dets) else []  # detections

    def get_dists(self, tracks, detections):
        """Calculates the distance between tracks and detections using IoU and optionally fuses scores."""
        dists = matching.iou_distance(tracks, detections)
        if self.args.fuse_score:
            dists = matching.fuse_score(dists, detections)
        return dists

    def multi_predict(self, tracks):
        """Predict the next states for multiple tracks using Kalman filter."""
        STrack.multi_predict(tracks)

    @staticmethod
    def reset_id():
        """Resets the ID counter for STrack instances to ensure unique track IDs across tracking sessions."""
        STrack.reset_id()

    def reset(self):
        """Resets the tracker by clearing all tracked, lost, and removed tracks and reinitializing the Kalman filter."""
        self.tracked_stracks = []  # type: list[STrack]
        self.lost_stracks = []  # type: list[STrack]
        self.removed_stracks = []  # type: list[STrack]
        self.frame_id = 0
        self.kalman_filter = self.get_kalmanfilter()
        self.reset_id()

        # é‡ç½®å…‰æµçŠ¶æ€
        self.flow_calculator.reset()
        self.last_velocity = (0, 0)
        self.reference_velocity = None
        self.in_compensation_mode = False

        # ä¿æŒè‡ªé€‚åº”å¡å°”æ›¼æ»¤æ³¢
        if self.always_adaptive:
            self.kalman_filter.noise_scale_factor = self.max_noise_scale
            self.args.match_thresh = self.max_match_thresh

    @staticmethod
    def joint_stracks(tlista, tlistb):
        """Combines two lists of STrack objects into a single list, ensuring no duplicates based on track IDs."""
        exists = {}
        res = []
        for t in tlista:
            exists[t.track_id] = 1
            res.append(t)
        for t in tlistb:
            tid = t.track_id
            if not exists.get(tid, 0):
                exists[tid] = 1
                res.append(t)
        return res

    @staticmethod
    def sub_stracks(tlista, tlistb):
        """Filters out the stracks present in the second list from the first list."""
        track_ids_b = {t.track_id for t in tlistb}
        return [t for t in tlista if t.track_id not in track_ids_b]

    @staticmethod
    def remove_duplicate_stracks(stracksa, stracksb):
        """Removes duplicate stracks from two lists based on Intersection over Union (IoU) distance."""
        pdist = matching.iou_distance(stracksa, stracksb)
        pairs = np.where(pdist < 0.15)
        dupa, dupb = [], []
        for p, q in zip(*pairs):
            timep = stracksa[p].frame_id - stracksa[p].start_frame
            timeq = stracksb[q].frame_id - stracksb[q].start_frame
            if timep > timeq:
                dupb.append(q)
            else:
                dupa.append(p)
        resa = [t for i, t in enumerate(stracksa) if i not in dupa]
        resb = [t for i, t in enumerate(stracksb) if i not in dupb]
        return resa, resb


# å¯è§†åŒ–å‡½æ•°
def visualize_compensation(img, pre_boxes, post_boxes):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶è¡¥å¿å‰åçš„è¾¹ç•Œæ¡†

    Args:
        img: è¾“å…¥å›¾åƒ
        pre_boxes: è¡¥å¿å‰çš„è¾¹ç•Œæ¡† [x1,y1,x2,y2,track_id,score,class,idx] æˆ– [cx,cy,w,h,angle,track_id,score,class,idx]
        post_boxes: è¡¥å¿åçš„è¾¹ç•Œæ¡†

    Returns:
        å¸¦æœ‰å¯è§†åŒ–ç»“æœçš„å›¾åƒ
    """
    # å¤åˆ¶å›¾åƒä»¥å…ä¿®æ”¹åŸå›¾
    vis_img = img.copy()

    # ç»˜åˆ¶è¡¥å¿å‰çš„æ¡†ï¼ˆçº¢è‰²ï¼‰
    if pre_boxes is not None:
        for box in pre_boxes:
            if len(box) >= 8:  # æ ‡å‡†æ ¼å¼
                if len(box) == 9:  # å¸¦è§’åº¦çš„æ¡†
                    cx, cy, w, h, angle = box[:5]
                    # ç»˜åˆ¶æ—‹è½¬æ¡†ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    rect = ((cx, cy), (w, h), angle * 180 / np.pi if np.isscalar(angle) else angle)
                    points = cv2.boxPoints(rect).astype(np.int32)
                    cv2.polylines(vis_img, [points], True, (0, 0, 255), 2)  # çº¢è‰²
                else:
                    x1, y1, x2, y2 = box[:4]
                    cv2.rectangle(vis_img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)  # çº¢è‰²

                # ç»˜åˆ¶ID
                track_id = int(box[-4])
                cv2.putText(vis_img, f"ID:{track_id}", (int(box[0]), int(box[1]) - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # ç»˜åˆ¶è¡¥å¿åçš„æ¡†ï¼ˆç»¿è‰²ï¼‰
    if post_boxes is not None:
        for box in post_boxes:
            if len(box) >= 8:  # æ ‡å‡†æ ¼å¼
                if len(box) == 9:  # å¸¦è§’åº¦çš„æ¡†
                    cx, cy, w, h, angle = box[:5]
                    # ç»˜åˆ¶æ—‹è½¬æ¡†
                    rect = ((cx, cy), (w, h), angle * 180 / np.pi if np.isscalar(angle) else angle)
                    points = cv2.boxPoints(rect).astype(np.int32)
                    cv2.polylines(vis_img, [points], True, (0, 255, 0), 2)  # ç»¿è‰²
                else:
                    x1, y1, x2, y2 = box[:4]
                    cv2.rectangle(vis_img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)  # ç»¿è‰²

                # ç»˜åˆ¶ID
                track_id = int(box[-4])
                cv2.putText(vis_img, f"ID:{track_id}", (int(box[0]), int(box[1]) + 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return vis_img